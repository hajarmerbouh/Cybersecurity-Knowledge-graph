{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Le but est de créer un jeu de données contenant les triplets généré à partir d'un ensemble de textes. \n",
        "\n",
        "- Source node , Target, Relationship label\n",
        "\n",
        "Puisque je vais construire le KG avec py2neo, j'aurai donc besoin même des étiquettes dans lesquels source et target nodes appartient. \n",
        "\n",
        "La sortie de ce notebook est une dataset contenant les triplets et les étiquettes; Ce jeu de donnée sera ensuite utilisé pour créer le graphe de connaissances"
      ],
      "metadata": {
        "id": "eQdXcPSwkEJh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "311eP72iZ5d_",
        "outputId": "67e6ae72-2d6c-4c3f-bd8d-7cecb9c7a480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import  drive\n",
        "drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-B3zH4C0JWj",
        "outputId": "bd11d7c3-4301-4237-8842-b98db483f0f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.21.6)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsK5ZuVGYT73"
      },
      "outputs": [],
      "source": [
        "GIT_URL_1 = \"https://github.com/kbandla/APTnotes\"\n",
        "GIT_URL_2 = \"https://github.com/CyberMonitor/APT_CyberCriminal_Campagin_Collections\"\n",
        "SOURCE_PDF_DIR='/drive/My Drive/PDF'\n",
        "DST_TXT_DIR='/drive/My Drive/TXT'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ52tc_2Y2dH"
      },
      "source": [
        "## **Download malwares reports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1JePLD0aIZR"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W-kE4SzYZSl"
      },
      "outputs": [],
      "source": [
        "def download_repo(github_url, dst_dir):\n",
        "    repo_name = github_url.split('/')[-1]\n",
        "    clone_bash_command = f\"git clone {github_url}.git {dst_dir}/{repo_name}\"\n",
        "    print(f\"Run: {clone_bash_command}\")\n",
        "    os.system(clone_bash_command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33-XWIZ3YdoO",
        "outputId": "8cb622a4-7f51-494d-ca6d-4b27b24ddb69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run: git clone https://github.com/kbandla/APTnotes.git /drive/My Drive/PDF/APTnotes\n"
          ]
        }
      ],
      "source": [
        "download_repo(GIT_URL_1, SOURCE_PDF_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kby-mdh3m_2Y",
        "outputId": "ab419905-c001-494b-da8f-1f7ed86c69b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '/drive/My Drive/PDF/APTnotes'...\n",
            "remote: Enumerating objects: 1612, done.\u001b[K\n",
            "remote: Total 1612 (delta 0), reused 0 (delta 0), pack-reused 1612\u001b[K\n",
            "Receiving objects: 100% (1612/1612), 456.14 MiB | 16.69 MiB/s, done.\n",
            "Resolving deltas: 100% (878/878), done.\n",
            "Checking out files: 100% (303/303), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kbandla/APTnotes.git '/drive/My Drive/PDF/APTnotes'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aUhP-rWY_iz"
      },
      "source": [
        "## **Convert PDF to TXT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJLHzC-1fbW4",
        "outputId": "16f44017-c5b4-4fdd-eb89-88a2ed036dd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpoppler-cpp0v5\n",
            "The following NEW packages will be installed:\n",
            "  libpoppler-cpp-dev libpoppler-cpp0v5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 36.7 kB of archives.\n",
            "After this operation, 188 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpoppler-cpp0v5 amd64 0.62.0-2ubuntu2.12 [28.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpoppler-cpp-dev amd64 0.62.0-2ubuntu2.12 [8,676 B]\n",
            "Fetched 36.7 kB in 0s (690 kB/s)\n",
            "Selecting previously unselected package libpoppler-cpp0v5:amd64.\n",
            "(Reading database ... 155657 files and directories currently installed.)\n",
            "Preparing to unpack .../libpoppler-cpp0v5_0.62.0-2ubuntu2.12_amd64.deb ...\n",
            "Unpacking libpoppler-cpp0v5:amd64 (0.62.0-2ubuntu2.12) ...\n",
            "Selecting previously unselected package libpoppler-cpp-dev:amd64.\n",
            "Preparing to unpack .../libpoppler-cpp-dev_0.62.0-2ubuntu2.12_amd64.deb ...\n",
            "Unpacking libpoppler-cpp-dev:amd64 (0.62.0-2ubuntu2.12) ...\n",
            "Setting up libpoppler-cpp0v5:amd64 (0.62.0-2ubuntu2.12) ...\n",
            "Setting up libpoppler-cpp-dev:amd64 (0.62.0-2ubuntu2.12) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!apt-get install libpoppler-cpp-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GtxqByZaeTv",
        "outputId": "df0deb90-c153-45d0-9ee8-502a35a96423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pdftotext\n",
            "  Using cached pdftotext-2.2.2.tar.gz (113 kB)\n",
            "Building wheels for collected packages: pdftotext\n",
            "  Building wheel for pdftotext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdftotext: filename=pdftotext-2.2.2-cp37-cp37m-linux_x86_64.whl size=54932 sha256=41c41745e0e649a953cbc8f886a490e7478824de2af07d7b5d77c3d2284b3efe\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/19/8e/e8648026db8b7ef3324ad9afa1f7c9109a7e7509846f693ed9\n",
            "Successfully built pdftotext\n",
            "Installing collected packages: pdftotext\n",
            "Successfully installed pdftotext-2.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pdftotext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El3mnvEt-lnH",
        "outputId": "c49da6cd-17b0-432e-f33a-972228b89a3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 11.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 53.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6jFbaPfajLC"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pdftotext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OHvPkfTZC-n"
      },
      "outputs": [],
      "source": [
        "def pdftotext_converter(source_pdf_dir, dst_txt_dir):\n",
        "    source_pdf_dir = Path(source_pdf_dir)\n",
        "    dst_txt_dir = Path(dst_txt_dir)\n",
        "    print(f\"pdf_dir : {source_pdf_dir}\")\n",
        "    print(f\"dst_txt_dir : {dst_txt_dir}\")\n",
        "    bad_counter = 0\n",
        "    for i, pdf_path in enumerate(source_pdf_dir.rglob(\"*pdf\")):\n",
        "        rel_pdf_path = pdf_path.relative_to(source_pdf_dir)\n",
        "        dst_path = dst_txt_dir / f\"{rel_pdf_path}.txt\"\n",
        "        dst_path.parent.mkdir(exist_ok=True, parents=True)\n",
        "        # Load your PDF\n",
        "        try:\n",
        "            with open(pdf_path, \"rb\") as f:\n",
        "                pdf = pdftotext.PDF(f)\n",
        "\n",
        "            with open(dst_path, 'w') as f:\n",
        "                f.write(\"\\n\\n\".join(pdf))\n",
        "\n",
        "            print(\"converted\", i - bad_counter, dst_path)\n",
        "        except Exception as e:\n",
        "            print(e, i, dst_path)\n",
        "            bad_counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oVOZ6XggghX",
        "outputId": "5e9a914e-4a80-4ab2-d064-8e887ec85ccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pdf_dir : /drive/My Drive/PDF/APTnotes\n",
            "dst_txt_dir : /drive/My Drive/TXT/APTnotes\n",
            "converted 0 /drive/My Drive/TXT/APTnotes/2008/556_10535_798405_Annex87_CyberAttacks.pdf.txt\n",
            "converted 1 /drive/My Drive/TXT/APTnotes/2009/ghostnet.pdf.txt\n",
            "converted 2 /drive/My Drive/TXT/APTnotes/2010/Aurora_Botnet_Command_Structure.pdf.txt\n",
            "converted 3 /drive/My Drive/TXT/APTnotes/2010/Aurora_HBGARY_DRAFT.pdf.txt\n",
            "converted 4 /drive/My Drive/TXT/APTnotes/2010/Case_Study_Operation_Aurora_V11.pdf.txt\n",
            "converted 5 /drive/My Drive/TXT/APTnotes/2010/Combating Threats - Operation Aurora.pdf.txt\n",
            "converted 6 /drive/My Drive/TXT/APTnotes/2010/MSUpdaterTrojanWhitepaper.pdf.txt\n",
            "converted 7 /drive/My Drive/TXT/APTnotes/2010/WhitePaper HBGary Threat Report, Operation Aurora.pdf.txt\n",
            "converted 8 /drive/My Drive/TXT/APTnotes/2010/how_can_u_tell_Aurora.pdf.txt\n",
            "converted 9 /drive/My Drive/TXT/APTnotes/2010/in-depth_analysis_of_hydraq_final_231538.pdf.txt\n",
            "converted 10 /drive/My Drive/TXT/APTnotes/2010/shadows-in-the-cloud.pdf.txt\n",
            "converted 11 /drive/My Drive/TXT/APTnotes/2011/Alerts DL-2011 Alerts-A-2011-02-18-01 Night Dragon Attachment 1.pdf.txt\n",
            "converted 12 /drive/My Drive/TXT/APTnotes/2011/C5_APT_ADecadeInReview.pdf.txt\n",
            "converted 13 /drive/My Drive/TXT/APTnotes/2011/C5_APT_SKHack.pdf.txt\n",
            "converted 14 /drive/My Drive/TXT/APTnotes/2011/Duqu_Trojan_Questions_and_Answers.pdf.txt\n",
            "converted 15 /drive/My Drive/TXT/APTnotes/2011/Evolution_Drivers_Duqu_Stuxnet.pdf.txt\n",
            "converted 16 /drive/My Drive/TXT/APTnotes/2011/HTran_and_the_Advanced_Persistent_Threat.pdf.txt\n",
            "converted 17 /drive/My Drive/TXT/APTnotes/2011/Palebot_Palestinian_credentials.pdf.txt\n",
            "converted 18 /drive/My Drive/TXT/APTnotes/2011/Stuxnet_Under_the_Microscope.pdf.txt\n",
            "converted 19 /drive/My Drive/TXT/APTnotes/2011/shady_rat_vanity.pdf.txt\n",
            "converted 20 /drive/My Drive/TXT/APTnotes/2011/tb_advanced_persistent_threats.pdf.txt\n",
            "converted 21 /drive/My Drive/TXT/APTnotes/2011/the_nitro_attacks.pdf.txt\n",
            "converted 22 /drive/My Drive/TXT/APTnotes/2011/w32_stuxnet_dossier.pdf.txt\n",
            "converted 23 /drive/My Drive/TXT/APTnotes/2011/wp-global-energy-cyberattacks-night-dragon.pdf.txt\n",
            "converted 24 /drive/My Drive/TXT/APTnotes/2011/wp-operation-shady-rat.pdf.txt\n",
            "converted 25 /drive/My Drive/TXT/APTnotes/2011/wp_dissecting-lurid-apt.pdf.txt\n",
            "converted 26 /drive/My Drive/TXT/APTnotes/2012/Crouching_tiger_hidden_dragon.pdf.txt\n",
            "converted 27 /drive/My Drive/TXT/APTnotes/2012/Crypto-DarkComet-Report.pdf.txt\n",
            "converted 28 /drive/My Drive/TXT/APTnotes/2012/Cyberattack_against_Israeli_and_Palestinian_targets.pdf.txt\n",
            "converted 29 /drive/My Drive/TXT/APTnotes/2012/FTA 1007 - Shamoon.pdf.txt\n",
            "converted 30 /drive/My Drive/TXT/APTnotes/2012/Faces_Ghost_RAT.pdf.txt\n",
            "converted 31 /drive/My Drive/TXT/APTnotes/2012/From-Bahrain-With-Love-FinFishers-Spy-Kit-Exposed.pdf.txt\n",
            "converted 32 /drive/My Drive/TXT/APTnotes/2012/IEXPL0RE_RAT.pdf.txt\n",
            "converted 33 /drive/My Drive/TXT/APTnotes/2012/NormanShark-MaudiOperation.pdf.txt\n",
            "converted 34 /drive/My Drive/TXT/APTnotes/2012/OSX_SabPub.pdf.txt\n",
            "converted 35 /drive/My Drive/TXT/APTnotes/2012/PEST-CONTROL.pdf.txt\n",
            "converted 36 /drive/My Drive/TXT/APTnotes/2012/The_Madi_Infostealers.pdf.txt\n",
            "converted 37 /drive/My Drive/TXT/APTnotes/2012/The_Mirage_Campaign.pdf.txt\n",
            "converted 38 /drive/My Drive/TXT/APTnotes/2012/The_Sin_Digoo_Affair.pdf.txt\n",
            "converted 39 /drive/My Drive/TXT/APTnotes/2012/Tibet_Lurk.pdf.txt\n",
            "converted 40 /drive/My Drive/TXT/APTnotes/2012/VOHO_WP_FINAL_READY-FOR-Publication-09242012_AC.pdf.txt\n",
            "converted 41 /drive/My Drive/TXT/APTnotes/2012/WickedRose_andNCPH.pdf.txt\n",
            "converted 42 /drive/My Drive/TXT/APTnotes/2012/kaspersky-lab-gauss.pdf.txt\n",
            "converted 43 /drive/My Drive/TXT/APTnotes/2012/skywiper.pdf.txt\n",
            "converted 44 /drive/My Drive/TXT/APTnotes/2012/the-elderwood-project.pdf.txt\n",
            "converted 45 /drive/My Drive/TXT/APTnotes/2012/trojan_taidoor-targeting_think_tanks.pdf.txt\n",
            "converted 46 /drive/My Drive/TXT/APTnotes/2012/w32_flamer_newsforyou.pdf.txt\n",
            "converted 47 /drive/My Drive/TXT/APTnotes/2012/wp_ixeshe.pdf.txt\n",
            "converted 48 /drive/My Drive/TXT/APTnotes/2012/wp_luckycat_redux.pdf.txt\n",
            "converted 49 /drive/My Drive/TXT/APTnotes/2012/wp_the-heartbeat-apt-campaign.pdf.txt\n",
            "converted 50 /drive/My Drive/TXT/APTnotes/2013/15-2013-youonlyclicktwice.pdf.txt\n",
            "converted 51 /drive/My Drive/TXT/APTnotes/2013/19-2013-acalltoharm.pdf.txt\n",
            "converted 52 /drive/My Drive/TXT/APTnotes/2013/2013-9.pdf.txt\n",
            "converted 53 /drive/My Drive/TXT/APTnotes/2013/2q-report-on-targeted-attack-campaigns.pdf.txt\n",
            "converted 54 /drive/My Drive/TXT/APTnotes/2013/ByeBye_Shell_target.pdf.txt\n",
            "converted 55 /drive/My Drive/TXT/APTnotes/2013/C5_APT_C2InTheFifthDomain.pdf.txt\n",
            "converted 56 /drive/My Drive/TXT/APTnotes/2013/Dark_Seoul_Cyberattack.pdf.txt\n",
            "converted 57 /drive/My Drive/TXT/APTnotes/2013/ETSO_APT_Attacks_Analysis.pdf.txt\n",
            "converted 58 /drive/My Drive/TXT/APTnotes/2013/FTA 1010 - njRAT The Saga Continues.pdf.txt\n",
            "converted 59 /drive/My Drive/TXT/APTnotes/2013/FireEye-Terminator_RAT.pdf.txt\n",
            "converted 60 /drive/My Drive/TXT/APTnotes/2013/India_Pak_Tranchulas.pdf.txt\n",
            "converted 61 /drive/My Drive/TXT/APTnotes/2013/Inside_Report_by_Infosec_Consortium.pdf.txt\n",
            "converted 62 /drive/My Drive/TXT/APTnotes/2013/KeyBoy_Vietnam_India.pdf.txt\n",
            "converted 63 /drive/My Drive/TXT/APTnotes/2013/Kimsuky.pdf.txt\n",
            "converted 64 /drive/My Drive/TXT/APTnotes/2013/Mandiant_APT1_Report.pdf.txt\n",
            "converted 65 /drive/My Drive/TXT/APTnotes/2013/McAfee_Labs_Threat_Advisory_Exploit_Operation_Red_Oct.pdf.txt\n",
            "converted 66 /drive/My Drive/TXT/APTnotes/2013/MiniDuke_Paper_Final.pdf.txt\n",
            "converted 67 /drive/My Drive/TXT/APTnotes/2013/NS-Unveiling-an-Indian-Cyberattack-Infrastructure_FINAL_Web.pdf.txt\n",
            "converted 68 /drive/My Drive/TXT/APTnotes/2013/NormanShark-MaudiOperation.pdf.txt\n",
            "converted 69 /drive/My Drive/TXT/APTnotes/2013/Norman_HangOver report_Executive Summary_042513.pdf.txt\n",
            "converted 70 /drive/My Drive/TXT/APTnotes/2013/Operation_DeputyDog.pdf.txt\n",
            "converted 71 /drive/My Drive/TXT/APTnotes/2013/Operation_EphemeralHydra.pdf.txt\n",
            "converted 72 /drive/My Drive/TXT/APTnotes/2013/Operation_Molerats.pdf.txt\n",
            "converted 73 /drive/My Drive/TXT/APTnotes/2013/Plugx_Smoaler.pdf.txt\n",
            "converted 74 /drive/My Drive/TXT/APTnotes/2013/Presentation_Targeted-Attacks_EN.pdf.txt\n",
            "converted 75 /drive/My Drive/TXT/APTnotes/2013/RAP002_APT1_Technical_backstage.1.0.pdf.txt\n",
            "converted 76 /drive/My Drive/TXT/APTnotes/2013/Safe-a-targeted-threat.pdf.txt\n",
            "converted 77 /drive/My Drive/TXT/APTnotes/2013/Secrets_of_the_Comfoo_Masters.pdf.txt\n",
            "converted 78 /drive/My Drive/TXT/APTnotes/2013/Securelist_RedOctober.pdf.txt\n",
            "converted 79 /drive/My Drive/TXT/APTnotes/2013/Securelist_RedOctober_Detail.pdf.txt\n",
            "converted 80 /drive/My Drive/TXT/APTnotes/2013/Surtr_Malware_Tibetan.pdf.txt\n",
            "converted 81 /drive/My Drive/TXT/APTnotes/2013/Trojan.APT.BaneChant.pdf.txt\n",
            "converted 82 /drive/My Drive/TXT/APTnotes/2013/Trojan.APT.Seinup.pdf.txt\n",
            "converted 83 /drive/My Drive/TXT/APTnotes/2013/US-13-Yarochkin-In-Depth-Analysis-of-Escalated-APT-Attacks-Slides.pdf.txt\n",
            "converted 84 /drive/My Drive/TXT/APTnotes/2013/Unveiling an Indian Cyberattack Infrastructure - appendixes.pdf.txt\n",
            "converted 85 /drive/My Drive/TXT/APTnotes/2013/circl-analysisreport-miniduke-stage3-public.pdf.txt\n",
            "converted 86 /drive/My Drive/TXT/APTnotes/2013/comment_crew_indicators_of_compromise.pdf.txt\n",
            "converted 87 /drive/My Drive/TXT/APTnotes/2013/dissecting-operation-troy.pdf.txt\n",
            "converted 88 /drive/My Drive/TXT/APTnotes/2013/energy-at-risk.pdf.txt\n",
            "converted 89 /drive/My Drive/TXT/APTnotes/2013/fireeye-china-chopper-report.pdf.txt\n",
            "converted 90 /drive/My Drive/TXT/APTnotes/2013/fireeye-malware-supply-chain.pdf.txt\n",
            "converted 91 /drive/My Drive/TXT/APTnotes/2013/fireeye-operation-ke3chang.pdf.txt\n",
            "converted 92 /drive/My Drive/TXT/APTnotes/2013/fireeye-poison-ivy-report.pdf.txt\n",
            "converted 93 /drive/My Drive/TXT/APTnotes/2013/fireeye-wwc-report.pdf.txt\n",
            "converted 94 /drive/My Drive/TXT/APTnotes/2013/fta-1009---njrat-uncovered-1.pdf.txt\n",
            "converted 95 /drive/My Drive/TXT/APTnotes/2013/hidden_lynx.pdf.txt\n",
            "converted 96 /drive/My Drive/TXT/APTnotes/2013/icefog.pdf.txt\n",
            "converted 97 /drive/My Drive/TXT/APTnotes/2013/kaspersky-the-net-traveler-part1-final.pdf.txt\n",
            "converted 98 /drive/My Drive/TXT/APTnotes/2013/miniduke_indicators_public.pdf.txt\n",
            "converted 99 /drive/My Drive/TXT/APTnotes/2013/stuxnet_0_5_the_missing_link.pdf.txt\n",
            "converted 100 /drive/My Drive/TXT/APTnotes/2013/themysteryofthepdf0-dayassemblermicrobackdoor.pdf.txt\n",
            "converted 101 /drive/My Drive/TXT/APTnotes/2013/theteamspystory_final_t2.pdf.txt\n",
            "converted 102 /drive/My Drive/TXT/APTnotes/2013/tr-12-circl-plugx-analysis-v1.pdf.txt\n",
            "converted 103 /drive/My Drive/TXT/APTnotes/2013/winnti-more-than-just-a-game-130410.pdf.txt\n",
            "converted 104 /drive/My Drive/TXT/APTnotes/2013/wp-fakem-rat.pdf.txt\n",
            "converted 105 /drive/My Drive/TXT/APTnotes/2014/ASERT-Threat-Intelligence-Brief-2014-07-Illuminating-Etumbot-APT.pdf.txt\n",
            "converted 106 /drive/My Drive/TXT/APTnotes/2014/AdversaryIntelligenceReport_DeepPanda_0 (1).pdf.txt\n",
            "converted 107 /drive/My Drive/TXT/APTnotes/2014/Aided_Frame_Aided_Direction.pdf.txt\n",
            "converted 108 /drive/My Drive/TXT/APTnotes/2014/Alienvault_Scanbox.pdf.txt\n",
            "converted 109 /drive/My Drive/TXT/APTnotes/2014/Anunak_APT_against_financial_institutions.pdf.txt\n",
            "converted 110 /drive/My Drive/TXT/APTnotes/2014/BlackEnergy2_Plugins_Router.pdf.txt\n",
            "converted 111 /drive/My Drive/TXT/APTnotes/2014/Chinese_MITM_Google.pdf.txt\n",
            "converted 112 /drive/My Drive/TXT/APTnotes/2014/CloudAtlas_RedOctober_APT.pdf.txt\n",
            "converted 113 /drive/My Drive/TXT/APTnotes/2014/Compromise_Greece_Beijing.pdf.txt\n",
            "converted 114 /drive/My Drive/TXT/APTnotes/2014/CrowdStrike_Flying_Kitten.pdf.txt\n",
            "converted 115 /drive/My Drive/TXT/APTnotes/2014/Cylance_Operation_Cleaver_Report.pdf.txt\n",
            "converted 116 /drive/My Drive/TXT/APTnotes/2014/DEEP_PANDA_Sakula.pdf.txt\n",
            "converted 117 /drive/My Drive/TXT/APTnotes/2014/Darwin_fav_APT_Group.pdf.txt\n",
            "converted 118 /drive/My Drive/TXT/APTnotes/2014/Democracy_HongKong_Under_Attack.pdf.txt\n",
            "converted 119 /drive/My Drive/TXT/APTnotes/2014/Derusbi_Server_Analysis-Final.pdf.txt\n",
            "converted 120 /drive/My Drive/TXT/APTnotes/2014/Dragonfly_Threat_Against_Western_Energy_Suppliers.pdf.txt\n",
            "converted 121 /drive/My Drive/TXT/APTnotes/2014/EB-YetiJuly2014-Public.pdf.txt\n",
            "converted 122 /drive/My Drive/TXT/APTnotes/2014/El_Machete.pdf.txt\n",
            "converted 123 /drive/My Drive/TXT/APTnotes/2014/EvilBunny_Suspect4_v1.0.pdf.txt\n",
            "converted 124 /drive/My Drive/TXT/APTnotes/2014/FTA 1001 FINAL 1.15.14.pdf.txt\n",
            "converted 125 /drive/My Drive/TXT/APTnotes/2014/FTA 1011 Follow UP.pdf.txt\n",
            "converted 126 /drive/My Drive/TXT/APTnotes/2014/FTA 1012 STTEAM Final.pdf.txt\n",
            "converted 127 /drive/My Drive/TXT/APTnotes/2014/FTA_1013_RAT_in_a_jar.pdf.txt\n",
            "converted 128 /drive/My Drive/TXT/APTnotes/2014/FTA_1014_Bots_Machines_and_the_Matrix.pdf.txt\n",
            "converted 129 /drive/My Drive/TXT/APTnotes/2014/GDATA_TooHash_CaseStudy_102014_EN_v1.pdf.txt\n",
            "converted 130 /drive/My Drive/TXT/APTnotes/2014/GData_Uroburos_RedPaper_EN_v1.pdf.txt\n",
            "converted 131 /drive/My Drive/TXT/APTnotes/2014/Gholee_Protective_Edge_themed_spear_phishing_campaign.pdf.txt\n",
            "converted 132 /drive/My Drive/TXT/APTnotes/2014/Group72_Opening_ZxShell.pdf.txt\n",
            "converted 133 /drive/My Drive/TXT/APTnotes/2014/Group_72.pdf.txt\n",
            "converted 134 /drive/My Drive/TXT/APTnotes/2014/HPSR SecurityBriefing_Episode16_NorthKorea.pdf.txt\n",
            "converted 135 /drive/My Drive/TXT/APTnotes/2014/Hikit_Analysis-Final.pdf.txt\n",
            "converted 136 /drive/My Drive/TXT/APTnotes/2014/ICS_Havex_backdoors.pdf.txt\n",
            "converted 137 /drive/My Drive/TXT/APTnotes/2014/KL_Epic_Turla_Technical_Appendix_20140806.pdf.txt\n",
            "converted 138 /drive/My Drive/TXT/APTnotes/2014/KL_report_syrian_malware.pdf.txt\n",
            "converted 139 /drive/My Drive/TXT/APTnotes/2014/Kaspersky_Lab_crouching_yeti_appendixes_eng_final.pdf.txt\n",
            "converted 140 /drive/My Drive/TXT/APTnotes/2014/Kaspersky_Lab_whitepaper_Regin_platform_eng.pdf.txt\n",
            "converted 141 /drive/My Drive/TXT/APTnotes/2014/Korplug_Afghanistan_Tajikistan.pdf.txt\n",
            "converted 142 /drive/My Drive/TXT/APTnotes/2014/LeoUncia_OrcaRat.pdf.txt\n",
            "converted 143 /drive/My Drive/TXT/APTnotes/2014/Micro-Targeted-Malvertising-WP-10-27-14-1.pdf.txt\n",
            "converted 144 /drive/My Drive/TXT/APTnotes/2014/Miniduke_twitter.pdf.txt\n",
            "converted 145 /drive/My Drive/TXT/APTnotes/2014/Modified_Binaries_Tor.pdf.txt\n",
            "converted 146 /drive/My Drive/TXT/APTnotes/2014/NYTimes_Attackers_Evolve_Quickly.pdf.txt\n",
            "converted 147 /drive/My Drive/TXT/APTnotes/2014/NetTraveler_Makeover_10th_Birthday.pdf.txt\n",
            "converted 148 /drive/My Drive/TXT/APTnotes/2014/OnionDuke_Tor.pdf.txt\n",
            "converted 149 /drive/My Drive/TXT/APTnotes/2014/Op_Clandestine_Fox.pdf.txt\n",
            "converted 150 /drive/My Drive/TXT/APTnotes/2014/Op_SnowMan_DeputyDog.pdf.txt\n",
            "converted 151 /drive/My Drive/TXT/APTnotes/2014/OperationCleaver_The_Notepad_Files.pdf.txt\n",
            "converted 152 /drive/My Drive/TXT/APTnotes/2014/OperationDoubleTap.pdf.txt\n",
            "converted 153 /drive/My Drive/TXT/APTnotes/2014/Operation_CloudyOmega_Ichitaro.pdf.txt\n",
            "converted 154 /drive/My Drive/TXT/APTnotes/2014/Operation_GreedyWonk.pdf.txt\n",
            "converted 155 /drive/My Drive/TXT/APTnotes/2014/Operation_Poisoned_Handover.pdf.txt\n",
            "converted 156 /drive/My Drive/TXT/APTnotes/2014/Operation_Poisoned_Hurricane.pdf.txt\n",
            "converted 157 /drive/My Drive/TXT/APTnotes/2014/Operation_SnowMan.pdf.txt\n",
            "converted 158 /drive/My Drive/TXT/APTnotes/2014/OrcaRAT.pdf.txt\n",
            "converted 159 /drive/My Drive/TXT/APTnotes/2014/PAN_Nitro.pdf.txt\n",
            "converted 160 /drive/My Drive/TXT/APTnotes/2014/Pitty_Tiger_Final_Report.pdf.txt\n",
            "converted 161 /drive/My Drive/TXT/APTnotes/2014/Regis_The_Intercept.pdf.txt\n",
            "converted 162 /drive/My Drive/TXT/APTnotes/2014/Reuters_Turla.pdf.txt\n",
            "converted 163 /drive/My Drive/TXT/APTnotes/2014/Sandworm_briefing2.pdf.txt\n",
            "converted 164 /drive/My Drive/TXT/APTnotes/2014/Sayad_Flying_Kitten_analysis.pdf.txt\n",
            "converted 165 /drive/My Drive/TXT/APTnotes/2014/Syrian_Malware_Team_BlackWorm.pdf.txt\n",
            "converted 166 /drive/My Drive/TXT/APTnotes/2014/TA14-353A_wiper.pdf.txt\n",
            "converted 167 /drive/My Drive/TXT/APTnotes/2014/Targeted_Attacks_Lense_NGO.pdf.txt\n",
            "converted 168 /drive/My Drive/TXT/APTnotes/2014/Targeting_Syrian_ISIS_Critics.pdf.txt\n",
            "converted 169 /drive/My Drive/TXT/APTnotes/2014/The_Epic_Turla_Operation.pdf.txt\n",
            "converted 170 /drive/My Drive/TXT/APTnotes/2014/The_Monju_Incident.pdf.txt\n",
            "converted 171 /drive/My Drive/TXT/APTnotes/2014/The_Siesta_Campaign.pdf.txt\n",
            "converted 172 /drive/My Drive/TXT/APTnotes/2014/The_Uroburos_case.pdf.txt\n",
            "converted 173 /drive/My Drive/TXT/APTnotes/2014/ThreatConnect_Operation_Arachnophobia_Report.pdf.txt\n",
            "converted 174 /drive/My Drive/TXT/APTnotes/2014/TrapX_ZOMBIE_Report_Final.pdf.txt\n",
            "converted 175 /drive/My Drive/TXT/APTnotes/2014/Turla_2_Penquin.pdf.txt\n",
            "converted 176 /drive/My Drive/TXT/APTnotes/2014/Vinself_steganography.pdf.txt\n",
            "converted 177 /drive/My Drive/TXT/APTnotes/2014/Wiper_Malware.pdf.txt\n",
            "converted 178 /drive/My Drive/TXT/APTnotes/2014/XSLCmd_OSX.pdf.txt\n",
            "converted 179 /drive/My Drive/TXT/APTnotes/2014/XtremeRAT_fireeye.pdf.txt\n",
            "converted 180 /drive/My Drive/TXT/APTnotes/2014/ZoxPNG_Full_Analysis-Final.pdf.txt\n",
            "converted 181 /drive/My Drive/TXT/APTnotes/2014/apt28.pdf.txt\n",
            "converted 182 /drive/My Drive/TXT/APTnotes/2014/bcs_wp_InceptionReport_EN_v12914.pdf.txt\n",
            "converted 183 /drive/My Drive/TXT/APTnotes/2014/blackenergy_whitepaper.pdf.txt\n",
            "converted 184 /drive/My Drive/TXT/APTnotes/2014/circl-tr25-analysis-turla-pfinet-snake-uroburos.pdf.txt\n",
            "converted 185 /drive/My Drive/TXT/APTnotes/2014/cosmicduke_whitepaper.pdf.txt\n",
            "converted 186 /drive/My Drive/TXT/APTnotes/2014/darkhotel_kl_07.11.pdf.txt\n",
            "converted 187 /drive/My Drive/TXT/APTnotes/2014/darkhotelappendixindicators_kl.pdf.txt\n",
            "converted 188 /drive/My Drive/TXT/APTnotes/2014/deep-panda-webshells.pdf.txt\n",
            "converted 189 /drive/My Drive/TXT/APTnotes/2014/fireeye-operation-quantum-entanglement.pdf.txt\n",
            "converted 190 /drive/My Drive/TXT/APTnotes/2014/fireeye-operation-saffron-rose.pdf.txt\n",
            "converted 191 /drive/My Drive/TXT/APTnotes/2014/fireeye-sidewinder-targeted-attack.pdf.txt\n",
            "converted 192 /drive/My Drive/TXT/APTnotes/2014/h12756-wp-shell-crew.pdf.txt\n",
            "converted 193 /drive/My Drive/TXT/APTnotes/2014/korea_power_plant_wiper.pdf.txt\n",
            "converted 194 /drive/My Drive/TXT/APTnotes/2014/operation-poisoned-helmand.pdf.txt\n",
            "converted 195 /drive/My Drive/TXT/APTnotes/2014/putter-panda.pdf.txt\n",
            "converted 196 /drive/My Drive/TXT/APTnotes/2014/pwc_ScanBox_framework.pdf.txt\n",
            "converted 197 /drive/My Drive/TXT/APTnotes/2014/regin-analysis.pdf.txt\n",
            "converted 198 /drive/My Drive/TXT/APTnotes/2014/roaming_tiger_zeronights_2014.pdf.txt\n",
            "converted 199 /drive/My Drive/TXT/APTnotes/2014/rpt-fin4.pdf.txt\n",
            "converted 200 /drive/My Drive/TXT/APTnotes/2014/sec14-paper-hardy.pdf.txt\n",
            "converted 201 /drive/My Drive/TXT/APTnotes/2014/sec14-paper-marczak.pdf.txt\n",
            "converted 202 /drive/My Drive/TXT/APTnotes/2014/snake_whitepaper.pdf.txt\n",
            "converted 203 /drive/My Drive/TXT/APTnotes/2014/sophos-rotten-tomato-campaign.pdf.txt\n",
            "converted 204 /drive/My Drive/TXT/APTnotes/2014/tactical-intelligence-bulletin---sofacy-phishing-.pdf.txt\n",
            "converted 205 /drive/My Drive/TXT/APTnotes/2014/targeted_attacks_against_the_energy_sector.pdf.txt\n",
            "converted 206 /drive/My Drive/TXT/APTnotes/2014/th3bug_Watering_Hole_PoisonIvy.pdf.txt\n",
            "converted 207 /drive/My Drive/TXT/APTnotes/2014/unveilingthemask_v1.0.pdf.txt\n",
            "converted 208 /drive/My Drive/TXT/APTnotes/2014/w32_regin_stage_1.pdf.txt\n",
            "converted 209 /drive/My Drive/TXT/APTnotes/2014/w64_regin_stage_1.pdf.txt\n",
            "converted 210 /drive/My Drive/TXT/APTnotes/2014/wp-operation-pawn-storm.pdf.txt\n",
            "converted 211 /drive/My Drive/TXT/APTnotes/2015/ANALYSIS-ON-APT-TO-BE-ATTACK-THAT-FOCUSING-ON-CHINAS-GOVERNMENT-AGENCY-.pdf.txt\n",
            "converted 212 /drive/My Drive/TXT/APTnotes/2015/Agent.BTZ_to_ComRAT.pdf.txt\n",
            "converted 213 /drive/My Drive/TXT/APTnotes/2015/Anthem_hack_all_roads_lead_to_China.pdf.txt\n",
            "converted 214 /drive/My Drive/TXT/APTnotes/2015/Attacks against Israeli & Palestinian interests - Cyber security updates.pdf.txt\n",
            "converted 215 /drive/My Drive/TXT/APTnotes/2015/Backdoor.Winnti_Trojan.Skelky.pdf.txt\n",
            "converted 216 /drive/My Drive/TXT/APTnotes/2015/BlueTermite_Japan.pdf.txt\n",
            "converted 217 /drive/My Drive/TXT/APTnotes/2015/Carbanak_APT_eng.pdf.txt\n",
            "converted 218 /drive/My Drive/TXT/APTnotes/2015/China_Peace_Palace.pdf.txt\n",
            "converted 219 /drive/My Drive/TXT/APTnotes/2015/CmstarDownloader_Lurid_Enfal_Cousin.pdf.txt\n",
            "converted 220 /drive/My Drive/TXT/APTnotes/2015/CozyDuke.pdf.txt\n",
            "converted 221 /drive/My Drive/TXT/APTnotes/2015/Cylance SPEAR Team_ A Threat Actor Resurfaces.pdf.txt\n",
            "poppler error creating document 222 /drive/My Drive/TXT/APTnotes/2015/DTL-06282015-01.pdf.txt\n",
            "converted 222 /drive/My Drive/TXT/APTnotes/2015/DTL-12012015-01.pdf.txt\n",
            "converted 223 /drive/My Drive/TXT/APTnotes/2015/Dino – the latest spying malware from an allegedly French espionage group analyzed.pdf.txt\n",
            "converted 224 /drive/My Drive/TXT/APTnotes/2015/Dissecting-LinuxMoose.pdf.txt\n",
            "converted 225 /drive/My Drive/TXT/APTnotes/2015/Dissecting-the-Kraken.pdf.txt\n",
            "converted 226 /drive/My Drive/TXT/APTnotes/2015/Duke_cloud_Linux.pdf.txt\n",
            "converted 227 /drive/My Drive/TXT/APTnotes/2015/Elephantosis.pdf.txt\n",
            "converted 228 /drive/My Drive/TXT/APTnotes/2015/Equation_group_questions_and_answers.pdf.txt\n",
            "converted 229 /drive/My Drive/TXT/APTnotes/2015/FSOFACY.pdf.txt\n",
            "converted 230 /drive/My Drive/TXT/APTnotes/2015/Forkmeiamfamous_SeaDuke.pdf.txt\n",
            "converted 231 /drive/My Drive/TXT/APTnotes/2015/GlobalThreatIntelReport.pdf.txt\n",
            "converted 232 /drive/My Drive/TXT/APTnotes/2015/Grabit.pdf.txt\n",
            "converted 233 /drive/My Drive/TXT/APTnotes/2015/Inception_APT_Analysis_Bluecoat.pdf.txt\n",
            "converted 234 /drive/My Drive/TXT/APTnotes/2015/Indicators_of_Compormise_Hellsing.pdf.txt\n",
            "converted 235 /drive/My Drive/TXT/APTnotes/2015/Inside_EquationDrug_Espionage_Platform.pdf.txt\n",
            "converted 236 /drive/My Drive/TXT/APTnotes/2015/Minerva_Clearsky_CopyKittens(11-23-15).pdf.txt\n",
            "converted 237 /drive/My Drive/TXT/APTnotes/2015/MiniDionis_CozyCar_Seaduke.pdf.txt\n",
            "converted 238 /drive/My Drive/TXT/APTnotes/2015/OceanLotusReport.pdf.txt\n",
            "converted 239 /drive/My Drive/TXT/APTnotes/2015/Operation RussianDoll.pdf.txt\n",
            "converted 240 /drive/My Drive/TXT/APTnotes/2015/Operation-Potao-Express_final_v2.pdf.txt\n",
            "converted 241 /drive/My Drive/TXT/APTnotes/2015/OperationClandestineWolf.pdf.txt\n",
            "converted 242 /drive/My Drive/TXT/APTnotes/2015/P2P_PlugX_Analysis.pdf.txt\n",
            "converted 243 /drive/My Drive/TXT/APTnotes/2015/PawnStorm_iOS.pdf.txt\n",
            "converted 244 /drive/My Drive/TXT/APTnotes/2015/Project_Cobra_Analysis.pdf.txt\n",
            "converted 245 /drive/My Drive/TXT/APTnotes/2015/Regin_Hopscotch_Legspin.pdf.txt\n",
            "converted 246 /drive/My Drive/TXT/APTnotes/2015/Scarab_Russian.pdf.txt\n",
            "converted 247 /drive/My Drive/TXT/APTnotes/2015/Skeleton_Key_Analysis.pdf.txt\n",
            "converted 248 /drive/My Drive/TXT/APTnotes/2015/Targeted-Attacks-against-Tibetan-and-Hong-Kong-Groups-Exploiting-CVE-2014-4114.pdf.txt\n",
            "converted 249 /drive/My Drive/TXT/APTnotes/2015/Terracotta-VPN-Report-Final-8-3.pdf.txt\n",
            "converted 250 /drive/My Drive/TXT/APTnotes/2015/Thamar-Reservoir.pdf.txt\n",
            "converted 251 /drive/My Drive/TXT/APTnotes/2015/The Chronicles of the Hellsing APT_ the Empire Strikes Back - Securelist.pdf.txt\n",
            "converted 252 /drive/My Drive/TXT/APTnotes/2015/The CozyDuke APT - Securelist.pdf.txt\n",
            "converted 253 /drive/My Drive/TXT/APTnotes/2015/The Naikon APT - Securelist.pdf.txt\n",
            "converted 254 /drive/My Drive/TXT/APTnotes/2015/The-Desert-Falcons-targeted-attacks.pdf.txt\n",
            "converted 255 /drive/My Drive/TXT/APTnotes/2015/TheNaikonAPT-MsnMM1.pdf.txt\n",
            "converted 256 /drive/My Drive/TXT/APTnotes/2015/TheNaikonAPT-MsnMM2.pdf.txt\n",
            "converted 257 /drive/My Drive/TXT/APTnotes/2015/The_Mystery_of_Duqu_2_0_a_sophisticated_cyberespionage_actor_returns.pdf.txt\n",
            "converted 258 /drive/My Drive/TXT/APTnotes/2015/Tibetan-Uprising-Day-Malware-Attacks_websitepdf.pdf.txt\n",
            "converted 259 /drive/My Drive/TXT/APTnotes/2015/UnFIN4ished_Business_pwd.pdf.txt\n",
            "converted 260 /drive/My Drive/TXT/APTnotes/2015/WateringHole_Aerospace_CVE-2015-5122_IsSpace.pdf.txt\n",
            "converted 261 /drive/My Drive/TXT/APTnotes/2015/WildNeutron_Economic_espionage.pdf.txt\n",
            "converted 262 /drive/My Drive/TXT/APTnotes/2015/apt29-hammertoss-stealthy-tactics-define-a.pdf.txt\n",
            "converted 263 /drive/My Drive/TXT/APTnotes/2015/butterfly-corporate-spies-out-for-financial-gain.pdf.txt\n",
            "converted 264 /drive/My Drive/TXT/APTnotes/2015/cto-tib-20150223-01a.pdf.txt\n",
            "converted 265 /drive/My Drive/TXT/APTnotes/2015/cto-tib-20150420-01a.pdf.txt\n",
            "converted 266 /drive/My Drive/TXT/APTnotes/2015/duqu2_crysys.pdf.txt\n",
            "converted 267 /drive/My Drive/TXT/APTnotes/2015/oil-tanker-en.pdf.txt\n",
            "converted 268 /drive/My Drive/TXT/APTnotes/2015/operation-arid-viper-whitepaper-en.pdf.txt\n",
            "converted 269 /drive/My Drive/TXT/APTnotes/2015/plugx-goes-to-the-registry-and-india.pdf.txt\n",
            "converted 270 /drive/My Drive/TXT/APTnotes/2015/rpt-apt30.pdf.txt\n",
            "converted 271 /drive/My Drive/TXT/APTnotes/2015/rpt-behind-the-syria-conflict.pdf.txt\n",
            "converted 272 /drive/My Drive/TXT/APTnotes/2015/rpt-southeast-asia-threat-landscape.pdf.txt\n",
            "converted 273 /drive/My Drive/TXT/APTnotes/2015/the-black-vine-cyberespionage-group.pdf.txt\n",
            "converted 274 /drive/My Drive/TXT/APTnotes/2015/unit42-operation-lotus-blossom.pdf.txt\n",
            "converted 275 /drive/My Drive/TXT/APTnotes/2015/volatile-cedar-technical-report.pdf.txt\n",
            "converted 276 /drive/My Drive/TXT/APTnotes/2015/waterbug-attack-group.pdf.txt\n",
            "converted 277 /drive/My Drive/TXT/APTnotes/2015/winnti_pharmaceutical.pdf.txt\n",
            "converted 278 /drive/My Drive/TXT/APTnotes/2015/wp-operation-tropic-trooper.pdf.txt\n",
            "converted 279 /drive/My Drive/TXT/APTnotes/2015/wp-operation-woolen-goldfish.pdf.txt\n",
            "converted 280 /drive/My Drive/TXT/APTnotes/historical/2008/Cyberwar.pdf.txt\n",
            "converted 281 /drive/My Drive/TXT/APTnotes/historical/2008/chinas-electronic.pdf.txt\n",
            "converted 282 /drive/My Drive/TXT/APTnotes/historical/2009/Ashmore - Impact of Alleged Russian Cyber Attacks .pdf.txt\n",
            "converted 283 /drive/My Drive/TXT/APTnotes/historical/2009/Cyber-030.pdf.txt\n",
            "converted 284 /drive/My Drive/TXT/APTnotes/historical/2009/DECLAWING THE DRAGON.pdf.txt\n",
            "converted 285 /drive/My Drive/TXT/APTnotes/historical/2011/CyberEspionage.pdf.txt\n",
            "converted 286 /drive/My Drive/TXT/APTnotes/historical/2011/enter-the-cyberdragon.pdf.txt\n",
            "converted 287 /drive/My Drive/TXT/APTnotes/historical/2011/vol7no2Ball.pdf.txt\n"
          ]
        }
      ],
      "source": [
        "pdftotext_converter('/drive/My Drive/PDF/APTnotes', '/drive/My Drive/TXT/APTnotes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INRAVkSKpF_8"
      },
      "source": [
        "## **Let's apply our best ner & RE model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvQ8LNNL3cug"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "from transformers import BertForTokenClassification, AdamW\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "from collections import OrderedDict\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from nltk import tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzPpCGHDZYAw"
      },
      "source": [
        "**Loading ner model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YapqzZ6g4EYk"
      },
      "outputs": [],
      "source": [
        "# If the tokenizer uses a single vocabulary file, you can point directly to this file\n",
        "tokenizer = AutoTokenizer.from_pretrained('/drive/My Drive/bestmodel/')\n",
        "model = AutoModelForTokenClassification.from_pretrained('/drive/My Drive/bestmodel/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifHuizuAGZJT"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpPZVg2JGOnq"
      },
      "outputs": [],
      "source": [
        "id2label= {\n",
        "    \"0\": \"B-ATTACKER\",\n",
        "    \"1\": \"I-ATTACKER\",\n",
        "    \"2\": \"B-COMPAIGN\",\n",
        "    \"3\": \"I-COMPAIGN\",\n",
        "    \"4\": \"B-DATE\",\n",
        "    \"5\": \"I-DATE\",\n",
        "    \"6\": \"B-ExploitTargetObject\",\n",
        "    \"7\": \"I-ExploitTargetObject\",\n",
        "    \"8\": \"B-INDICATOR\",\n",
        "    \"9\": \"I-INDICATOR\",\n",
        "    \"10\": \"B-INFORMATION\",\n",
        "    \"11\": \"I-INFORMATION\",\n",
        "    \"12\": \"B-LOC\",\n",
        "    \"13\": \"I-LOC\",\n",
        "    \"14\": \"B-MALWARE\",\n",
        "    \"15\": \"I-MALWARE\",\n",
        "    \"16\": \"B-MALWARECHARACTERISTICS\",\n",
        "    \"17\": \"I-MALWARECHARACTERISTICS\",\n",
        "    \"18\": \"B-ORG\",\n",
        "    \"19\": \"I-ORG\",\n",
        "    \"20\": \"B-PRODUCT\",\n",
        "    \"21\": \"I-PRODUCT\",\n",
        "    \"22\": \"B-VULNERABILITY\",\n",
        "    \"23\": \"I-VULNERABILITY\",\n",
        "    \"24\": \"O\"\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxRSznreazXA",
        "outputId": "9199d1aa-51ab-46aa-d9ad-cb979f9d83a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=25, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OobZr9PkZeos"
      },
      "source": [
        "**Loading relation extraction model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdJQ5wbqlIiX"
      },
      "outputs": [],
      "source": [
        "rel2id={'<pad>': 0,\n",
        " 'authored(e1,e2)': 20,\n",
        " 'authored(e2,e1)': 19,\n",
        " 'belongsto(e1,e2)': 25,\n",
        " 'belongsto(e2,e1)': 6,\n",
        " 'exploits(e1,e2)': 9,\n",
        " 'exploits(e2,e1)': 11,\n",
        " 'hasattacklocation(e1,e2)': 7,\n",
        " 'hasattacklocation(e2,e1)': 5,\n",
        " 'hasattacktime(e1,e2)': 1,\n",
        " 'hasattacktime(e2,e1)': 14,\n",
        " 'hascharacteristics(e1,e2)': 15,\n",
        " 'hascharacteristics(e2,e1)': 21,\n",
        " 'hasproduct(e1,e2)': 13,\n",
        " 'hasproduct(e2,e1)': 18,\n",
        " 'hasvulnerability(e1,e2)': 3,\n",
        " 'hasvulnerability(e2,e1)': 10,\n",
        " 'indicates(e1,e2)': 12,\n",
        " 'indicates(e2,e1)': 2,\n",
        " 'involvesmalware(e1,e2)': 22,\n",
        " 'involvesmalware(e2,e1)': 23,\n",
        " 'other': 8,\n",
        " 'targets(e1,e2)': 4,\n",
        " 'targets(e2,e1)': 17,\n",
        " 'usesmalware(e1,e2)': 24,\n",
        " 'usesmalware(e2,e1)': 16}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDZWE_vnZ6_j"
      },
      "outputs": [],
      "source": [
        "id2rel={0: '<pad>',\n",
        " 1: 'hasattacktime(e1,e2)',\n",
        " 2: 'indicates(e2,e1)',\n",
        " 3: 'hasvulnerability(e1,e2)',\n",
        " 4: 'targets(e1,e2)',\n",
        " 5: 'hasattacklocation(e2,e1)',\n",
        " 6: 'belongsto(e2,e1)',\n",
        " 7: 'hasattacklocation(e1,e2)',\n",
        " 8: 'other',\n",
        " 9: 'exploits(e1,e2)',\n",
        " 10: 'hasvulnerability(e2,e1)',\n",
        " 11: 'exploits(e2,e1)',\n",
        " 12: 'indicates(e1,e2)',\n",
        " 13: 'hasproduct(e1,e2)',\n",
        " 14: 'hasattacktime(e2,e1)',\n",
        " 15: 'hascharacteristics(e1,e2)',\n",
        " 16: 'usesmalware(e2,e1)',\n",
        " 17: 'targets(e2,e1)',\n",
        " 18: 'hasproduct(e2,e1)',\n",
        " 19: 'authored(e2,e1)',\n",
        " 20: 'authored(e1,e2)',\n",
        " 21: 'hascharacteristics(e2,e1)',\n",
        " 22: 'involvesmalware(e1,e2)',\n",
        " 23: 'involvesmalware(e2,e1)',\n",
        " 24: 'usesmalware(e1,e2)',\n",
        " 25: 'belongsto(e1,e2)'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EwIXuFCgHVD"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "file = open(\"w2id.txt\", \"r\")\n",
        "\n",
        "contents = file.read()\n",
        "word2id = ast.literal_eval(contents)\n",
        "\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1XWFzaSEpnv"
      },
      "outputs": [],
      "source": [
        "word_vec=torch.load('/drive/My Drive/tensors.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OgKK_wCgls7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def search_entity(sentence):\n",
        "    e1 = re.findall(r'<e1>(.*)</e1>', sentence)[0]\n",
        "    e2 = re.findall(r'<e2>(.*)</e2>', sentence)[0]\n",
        "    sentence = sentence.replace('<e1>' + e1 + '</e1>', ' <e1> ' + e1 + ' </e1> ', 1)\n",
        "    sentence = sentence.replace('<e2>' + e2 + '</e2>', ' <e2> ' + e2 + ' </e2> ', 1)\n",
        "    sentence = sentence.split()\n",
        "    sentence = ' '.join(sentence)\n",
        "    sentence = sentence.replace('< e1 >', '<e1>')\n",
        "    sentence = sentence.replace('< e2 >', '<e2>')\n",
        "    sentence = sentence.replace('< /e1 >', '</e1>')\n",
        "    sentence = sentence.replace('< /e2 >', '</e2>')\n",
        "    sentence = sentence.split()\n",
        "\n",
        "    assert '<e1>' in sentence\n",
        "    assert '<e2>' in sentence\n",
        "    assert '</e1>' in sentence\n",
        "    assert '</e2>' in sentence\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SM6WYec5a5ys"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "def convert(path_src, path_des):\n",
        "    with open(path_src, 'r', encoding='utf-8') as fr:\n",
        "        data = fr.readlines()\n",
        "        \n",
        "    with open(path_des, 'w', encoding='utf-8') as fw:\n",
        "        for i in range(0, len(data), 3):\n",
        "            id_s, sentence = data[i].strip().split('  ')\n",
        "            sentence = sentence[1:len(sentence)]\n",
        "            sentence = search_entity(sentence)\n",
        "            meta = dict(\n",
        "                id=id_s,\n",
        "                relation=data[i+1].strip(),\n",
        "                sentence=sentence,\n",
        "                \n",
        "            )\n",
        "            json.dump(meta, fw, ensure_ascii=False)\n",
        "            fw.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-Az1YBbbTxf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "class BrevetsDataLoader(object):\n",
        "    def __init__(self, rel2id, word2id, batch_size, max_len):\n",
        "        self.rel2id = rel2id\n",
        "        self.word2id = word2id\n",
        "        self.batch_size = batch_size\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __collate_fn(self, batch):\n",
        "        data = zip(*batch)  # unzip the batch data\n",
        "        data = list(data)\n",
        "        #label = list(label)\n",
        "        data = torch.from_numpy(np.concatenate(data, axis=0))\n",
        "        #label = torch.from_numpy(np.asarray(label, dtype=np.int64))\n",
        "        return data\n",
        "\n",
        "    def __get_data(self, filename,  shuffle=False):\n",
        "        dataset = BrevetsDateset(filename, self.rel2id, self.word2id, self.max_len)\n",
        "        loader = DataLoader(\n",
        "            dataset=dataset,\n",
        "            batch_size= self.batch_size,\n",
        "            shuffle=shuffle,\n",
        "            num_workers=2,\n",
        "            collate_fn=self.__collate_fn\n",
        "        )\n",
        "        return loader\n",
        "    def get_test(self):\n",
        "        return self.__get_data('sentence.json', shuffle=False)\n",
        "\n",
        "batch_size = 10\n",
        "max_len = 500\n",
        "loader = BrevetsDataLoader(rel2id, word2id, batch_size, max_len)\n",
        "\n",
        "#test_loader = loader.get_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5df5txlDPct"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "class Att_BLSTM(nn.Module):\n",
        "    def __init__(self, word_vec, class_num, max_len, word_dim, hidden_size, layers_num, dropout):\n",
        "        super().__init__()\n",
        "        self.word_vec = word_vec\n",
        "        self.class_num = class_num\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.word_dim = word_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.layers_num = layers_num\n",
        "        self.dropout_value = dropout\n",
        "\n",
        "        self.word_embedding = nn.Embedding.from_pretrained(\n",
        "            embeddings=self.word_vec,\n",
        "            freeze=False,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.word_dim,\n",
        "            hidden_size=self.hidden_size,\n",
        "            num_layers=self.layers_num,\n",
        "            bias=True,\n",
        "            batch_first=True,\n",
        "            dropout=self.dropout_value,\n",
        "            bidirectional=True,\n",
        "        )\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.dropout = nn.Dropout(self.dropout_value)\n",
        "\n",
        "        self.att_weight = nn.Parameter(torch.randn(1, self.hidden_size, 1))\n",
        "        self.dense = nn.Linear(\n",
        "            in_features=self.hidden_size,\n",
        "            out_features=self.class_num,\n",
        "            bias=True\n",
        "        )\n",
        "        init.xavier_normal_(self.dense.weight)\n",
        "        init.constant_(self.dense.bias, 0.)\n",
        "\n",
        "    def lstm_layer(self, x, mask):\n",
        "        lengths = torch.sum(mask.gt(0), dim=-1)\n",
        "        x = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
        "        h, (_, _) = self.lstm(x)\n",
        "        h, _ = pad_packed_sequence(h, batch_first=True, padding_value=0.0, total_length=self.max_len)\n",
        "        h = h.view(-1, self.max_len, 2, self.hidden_size)\n",
        "        h = torch.sum(h, dim=2)  \n",
        "        return h\n",
        "\n",
        "    def attention_layer(self, h, mask):\n",
        "        att_weight = self.att_weight.expand(mask.shape[0], -1, -1) \n",
        "        att_score = torch.bmm(self.tanh(h), att_weight)  \n",
        "        mask = mask.unsqueeze(dim=-1)  \n",
        "        att_score = att_score.masked_fill(mask.eq(0), float('-inf')) \n",
        "        att_weight = F.softmax(att_score, dim=1) \n",
        "        reps = torch.bmm(h.transpose(1, 2), att_weight).squeeze(dim=-1) \n",
        "        reps = self.tanh(reps)  \n",
        "        return reps\n",
        "\n",
        "    def forward(self, data):\n",
        "        token = data[:, 0, :].contiguous().view(-1, self.max_len)\n",
        "        mask = data[:, 1, :].contiguous().view(-1, self.max_len)\n",
        "        emb = self.word_embedding(token) \n",
        "        emb = self.dropout(emb)\n",
        "        h = self.lstm_layer(emb, mask) \n",
        "        h = self.dropout(h)\n",
        "        reps = self.attention_layer(h, mask) \n",
        "        reps = self.dropout(reps)\n",
        "        logits = self.dense(reps)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2IYncqRDQZ1",
        "outputId": "fd25ecec-885a-4a00-ab58-07a8d9a81022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ],
      "source": [
        "model_re = Att_BLSTM(word_vec = word_vec, class_num = 26, max_len = 500, word_dim = 300, hidden_size = 100, layers_num = 1, dropout = 0.5).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHaPdaUpF1cn",
        "outputId": "1c720fe0-d3ff-40c5-e735-066bb048877e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Att_BLSTM(\n",
              "  (word_embedding): Embedding(400006, 300)\n",
              "  (lstm): LSTM(300, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "  (tanh): Tanh()\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (dense): Linear(in_features=100, out_features=26, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model_re.load_state_dict(torch.load('/drive/My Drive/tut2-model_ner.pt'))\n",
        "model_re.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXKXQUCkF4Cd"
      },
      "outputs": [],
      "source": [
        "def align_tokens_and_predicted_labels(toks_cpu, preds_cpu):\n",
        "  aligned_toks, aligned_preds = [], []\n",
        "  prev_tok = None\n",
        "  for tok, pred in zip(toks_cpu, preds_cpu):\n",
        "    if tok.startswith(\"##\") and prev_tok is not None:\n",
        "      prev_tok += tok[2:]\n",
        "    else:\n",
        "      if prev_tok is not None:\n",
        "        aligned_toks.append(prev_tok)\n",
        "        aligned_preds.append(id2label[str(prev_pred)])\n",
        "      prev_tok = tok\n",
        "      prev_pred = pred\n",
        "  if prev_tok is not None:\n",
        "    aligned_toks.append(prev_tok)\n",
        "    aligned_preds.append(id2label[str(prev_pred)])\n",
        "  return aligned_toks, aligned_preds\n",
        "\n",
        "\n",
        "def predict(texts):\n",
        "  aligned_tok_list, aligned_pred_list = [], []\n",
        "  for text in texts:\n",
        "    \n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "    outputs = model(**inputs)\n",
        "    tokens_cpu = tokenizer.convert_ids_to_tokens(inputs.input_ids.view(-1))\n",
        "    preds_cpu = torch.argmax(outputs.logits, dim=-1)[0].cpu().numpy()\n",
        "\n",
        "    aligned_toks, aligned_preds = align_tokens_and_predicted_labels(tokens_cpu, preds_cpu)\n",
        "\n",
        "    aligned_tok_list.append(aligned_toks)\n",
        "    aligned_pred_list.append(aligned_preds)\n",
        "\n",
        "  return aligned_tok_list, aligned_pred_list\n",
        "\n",
        "\n",
        "predicted_tokens, predicted_tags = predict([\n",
        "         [\"Marie Curie won the Nobel Prize in 1903 and 1911 .Joe Biden is the current President of the United States .\"],\n",
        "         [\"Joe Biden is the current President of the United States .\"]\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFgbzuUOg4iq"
      },
      "outputs": [],
      "source": [
        "predicted_tokens, predicted_tags = predict([\n",
        "         [\"Marie Curie won the Nobel Prize in 1903 and 1911 .Joe Biden is the current President of the United States .\"],\n",
        "         [\"Joe Biden is the current President of the United States .\"]\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1-8yFBPbAq1"
      },
      "source": [
        "### After loading best ner & re models , let's apply them to our corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6ZDwDNC2YL4"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "path='/drive/My Drive/TXT/APTnotes'\n",
        "all_files = glob.glob(path + \"/*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myZX6CqgeH5s",
        "outputId": "9cb63324-b94d-4bbc-9b7c-3afecc9d68ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/drive/My Drive/TXT/APTnotes/2008/556_10535_798405_Annex87_CyberAttacks.pdf.txt\n",
            "/drive/My Drive/TXT/APTnotes/2009/ghostnet.pdf.txt\n",
            "/drive/My Drive/TXT/APTnotes/2010/Aurora_Botnet_Command_Structure.pdf.txt\n",
            "/drive/My Drive/TXT/APTnotes/2011/Alerts DL-2011 Alerts-A-2011-02-18-01 Night Dragon Attachment 1.pdf.txt\n",
            "/drive/My Drive/TXT/APTnotes/2012/Crouching_tiger_hidden_dragon.pdf.txt\n",
            "/drive/My Drive/TXT/APTnotes/2013/15-2013-youonlyclicktwice.pdf.txt\n",
            "/drive/My Drive/TXT/APTnotes/2014/ASERT-Threat-Intelligence-Brief-2014-07-Illuminating-Etumbot-APT.pdf.txt\n",
            "/drive/My Drive/TXT/APTnotes/2015/ANALYSIS-ON-APT-TO-BE-ATTACK-THAT-FOCUSING-ON-CHINAS-GOVERNMENT-AGENCY-.pdf.txt\n"
          ]
        }
      ],
      "source": [
        "for j in all_files:\n",
        "  text_files=glob.glob(j +\"/*.txt\")\n",
        "  for x in text_files:\n",
        "      print(x)\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kyw0MJWX77hy"
      },
      "source": [
        "- read each file\n",
        "- get sentences\n",
        "- extract entities from each sentence using ner model\n",
        "- if a sentence got two entities : surround them with la balise e then apply relation extraction model \n",
        "- store in a dataframe the following informations : \"entity1\" , \"tag1\", \"relation_label\",\"entity2\",\"tag2\"\n",
        "- create a kg using py2neo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_yD95zdiPf4"
      },
      "outputs": [],
      "source": [
        "source=[]\n",
        "target=[]\n",
        "relation=[]\n",
        "tags1=[]\n",
        "tags2=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92WZ7PPfj1wi"
      },
      "outputs": [],
      "source": [
        "def get_prediction(model, iterator):\n",
        "  predict_label=[]\n",
        "  for _, data in enumerate(iterator):\n",
        "            data = data.to(device)\n",
        "\n",
        "            logits = model(data)\n",
        "            \n",
        "\n",
        "            _, pred = torch.max(logits, dim=1)  \n",
        "            pred = pred.cpu().detach().numpy().reshape((-1, 1))\n",
        "            predict_label.append(pred)\n",
        "            predict_label = np.concatenate(predict_label, axis=0).reshape(-1).astype(np.int64)\n",
        "  return(predict_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4UWgV5yNLaE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9D8dKMqBWpG"
      },
      "outputs": [],
      "source": [
        "class BrevetsDateset(Dataset):\n",
        "    def __init__(self, filename, rel2id, word2id, max_len):\n",
        "        self.filename = filename\n",
        "        self.rel2id = rel2id\n",
        "        self.word2id = word2id\n",
        "        self.max_len = max_len\n",
        "        self.data_dir = ''\n",
        "        self.dataset = self.__load_data()\n",
        "\n",
        "    def __symbolize_sentence(self, sentence):\n",
        "      \n",
        "        mask = [1] * len(sentence)\n",
        "        words = []\n",
        "        length = min(self.max_len, len(sentence))\n",
        "        mask = mask[:length]\n",
        "\n",
        "        for i in range(length):\n",
        "            words.append(self.word2id.get(sentence[i].lower(), self.word2id['UNK']))\n",
        "\n",
        "        if length < self.max_len:\n",
        "            for i in range(length, self.max_len):\n",
        "                mask.append(0)  # 'PAD' mask is zero\n",
        "                words.append(self.word2id['PAD'])\n",
        "\n",
        "        unit = np.asarray([words, mask], dtype=np.int64)\n",
        "        unit = np.reshape(unit, newshape=(1, 2, self.max_len))\n",
        "        return unit\n",
        "\n",
        "    def __load_data(self):\n",
        "        path_data_file = os.path.join(self.data_dir, self.filename)\n",
        "        data = []\n",
        "        #labels = []\n",
        "        with open(path_data_file, 'r', encoding='utf-8') as fr:\n",
        "            for line in fr:\n",
        "                line = json.loads(line.strip())\n",
        "                #label = line['relation']\n",
        "                sentence = line['sentence']\n",
        "                #label_idx = self.rel2id[label]\n",
        "\n",
        "                one_sentence = self.__symbolize_sentence(sentence)\n",
        "                data.append(one_sentence)\n",
        "                #labels.append(label_idx)\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        index=0\n",
        "        data = self.dataset[index]\n",
        "        #label = self.label[index]\n",
        "        return data\n",
        "    def __len__(self):\n",
        "        return len('relation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfxRfD7UBeha",
        "outputId": "cf3d6756-284e-47a9-cb3f-229eab7e0a1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEOV7x1EBkq7"
      },
      "outputs": [],
      "source": [
        "# remove extra spaces and ending space if any\n",
        "import re\n",
        "spaces = ['\\u200b', '\\u200e', '\\u202a', '\\u202c', '\\ufeff', '\\uf0d8', '\\u2061', '\\x10', '\\x7f', '\\x9d', '\\xad', '\\xa0']\n",
        "def remove_space(text):\n",
        "    for space in spaces:\n",
        "        text = text.replace(space, ' ')\n",
        "    text = text.strip()\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFtcvOwG2mNS"
      },
      "outputs": [],
      "source": [
        "id=0\n",
        "for folder in all_files:\n",
        "  text_files=glob.glob(folder +\"/*.txt\")\n",
        "  for file in text_files:\n",
        "    with open(file, 'r', encoding = 'utf-8') as f:\n",
        "        text = f.read()\n",
        "    text=text.replace('\\n',' ')\n",
        "    text=remove_space(text)\n",
        "    sentences=tokenize.sent_tokenize(text)\n",
        "    sentences=[[s[:513]] for s in sentences] # I returned it this form so that i can apply ner model on each sentence  \n",
        "    predicted_tokens, predicted_tags = predict(sentences)\n",
        "    for i in range (len(sentences)):\n",
        "      firstTag=True\n",
        "      sentence=\"\"\n",
        "      other=['O' for o in range (len(predicted_tags[i]))] # sentence which doesnt contain any tag\n",
        "      if predicted_tags[i] != other: \n",
        "        for tok in range (len(predicted_tokens[i])):\n",
        "          if predicted_tags[i][tok]=='O':\n",
        "            sentence=sentence+' '+predicted_tokens[i][tok]\n",
        "          elif predicted_tokens[i][tok]!='[SEP]' and predicted_tags[i][tok].startswith('B-') and firstTag:\n",
        "            tag1=predicted_tags[i][tok][2:]\n",
        "            if tok!=(len(predicted_tags[i])-1) and predicted_tags[i][tok+1].startswith('I-'):\n",
        "              sentence=sentence+' '+'<e1>'+predicted_tokens[i][tok]\n",
        "            else:\n",
        "              sentence=sentence+' '+'<e1>'+predicted_tokens[i][tok]+'</e1>'\n",
        "            firstTag=False\n",
        "          elif predicted_tokens[i][tok]!='[SEP]' and predicted_tags[i][tok].startswith('B-') and firstTag is False:\n",
        "            tag2=predicted_tags[i][tok][2:]\n",
        "            if tok!=(len(predicted_tags[i])-1) and predicted_tags[i][tok+1].startswith('I-') and predicted_tokens[i][tok+1]!='[SEP]':\n",
        "              sentence=sentence+' '+'<e2>'+predicted_tokens[i][tok]\n",
        "            else:\n",
        "              sentence=sentence+' '+'<e2>'+predicted_tokens[i][tok]+'</e2>'\n",
        "          else:\n",
        "            if predicted_tokens[i][tok]!='[SEP]':\n",
        "              if tok!=(len(predicted_tags[i])-1) and predicted_tags[i][tok+1].startswith('I-') and predicted_tokens[i][tok+1]!='[SEP]' :\n",
        "                 sentence=sentence+' '+predicted_tokens[i][tok]\n",
        "              else:\n",
        "                 if \"<e2>\" in sentence:\n",
        "                   sentence=sentence+' '+predicted_tokens[i][tok]+\"</e2>\"\n",
        "                 else:\n",
        "                   sentence=sentence+' '+predicted_tokens[i][tok]+'</e1>'\n",
        "\n",
        "\n",
        "      if sentence.count(\"<e1>\")==1 and sentence.count(\"<e2>\")==1:\n",
        "        m=sentence.find('<e1>')  \n",
        "        n=sentence.find('</e1>')\n",
        "        k=m+4\n",
        "        entity1=sentence[k:n] \n",
        "        p= sentence.find('<e2>')\n",
        "        q=sentence.find('</e2>')\n",
        "        y=p+4\n",
        "        entity2=sentence[y:q]\n",
        "        #write sentence in text file\n",
        "        with open('sentence.txt', 'w') as f:\n",
        "           id=1\n",
        "           f.write(str(id)+'  '+sentence)\n",
        "           f.write(\"\\n\")\n",
        "           f.write('relation')\n",
        "        f.close()\n",
        "        convert('sentence.txt','sentence.json')\n",
        "        test_loader = loader.get_test()\n",
        "        pred=get_prediction(model_re, test_loader)\n",
        "        rel=id2rel[pred[0]]\n",
        "        if \"(e1,e2)\" in rel:\n",
        "          source.append(entity1)\n",
        "          target.append(entity2)\n",
        "          relation.append(rel[:-7])\n",
        "          tags1.append(tag1)\n",
        "          tags2.append(tag2)\n",
        "        else:\n",
        "          source.append(entity2)\n",
        "          target.append(entity1)\n",
        "          relation.append(rel[:-7])\n",
        "          tags1.append(tag2)\n",
        "          tags2.append(tag1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59eUimG6Bam8"
      },
      "outputs": [],
      "source": [
        "data2=pd.DataFrame({\n",
        "    'source':source,\n",
        "    'tag1':tags1,\n",
        "    'relation_label':relation,\n",
        "    'target':target,\n",
        "    'tag2':tags2\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UpMOcc_qS3em",
        "outputId": "04857f88-126d-44ea-eaab-1df74882a677"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        source      tag1     relation_label   target     tag2\n",
              "0    Microsoft       ORG         hasproduct  Windows  PRODUCT\n",
              "1    Microsoft       ORG         hasproduct   PsExec  PRODUCT\n",
              "2        Adobe       ORG         hasproduct  Acrobat  PRODUCT\n",
              "3  BlackEnergy       ORG         hasproduct  Trojans  PRODUCT\n",
              "4         Tsai  ATTACKER  hasattacklocation    China      LOC"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-086df105-2f63-452d-8080-788d98882c88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>tag1</th>\n",
              "      <th>relation_label</th>\n",
              "      <th>target</th>\n",
              "      <th>tag2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Microsoft</td>\n",
              "      <td>ORG</td>\n",
              "      <td>hasproduct</td>\n",
              "      <td>Windows</td>\n",
              "      <td>PRODUCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Microsoft</td>\n",
              "      <td>ORG</td>\n",
              "      <td>hasproduct</td>\n",
              "      <td>PsExec</td>\n",
              "      <td>PRODUCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adobe</td>\n",
              "      <td>ORG</td>\n",
              "      <td>hasproduct</td>\n",
              "      <td>Acrobat</td>\n",
              "      <td>PRODUCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BlackEnergy</td>\n",
              "      <td>ORG</td>\n",
              "      <td>hasproduct</td>\n",
              "      <td>Trojans</td>\n",
              "      <td>PRODUCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tsai</td>\n",
              "      <td>ATTACKER</td>\n",
              "      <td>hasattacklocation</td>\n",
              "      <td>China</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-086df105-2f63-452d-8080-788d98882c88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-086df105-2f63-452d-8080-788d98882c88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-086df105-2f63-452d-8080-788d98882c88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "data2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1G_ywb_pMq8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "group=pd.read_csv('/drive/My Drive/ATT&CK MATRICES Group.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "E6Mklfymptwb",
        "outputId": "ac89ecb0-7f02-4df4-a662-dbd97832cff3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Name     ID                                 Tecs Used by Group  \\\n",
              "0  admin@338  G0018  ['T1087', 'T1059', 'T1203', 'T1083', 'T1036', ...   \n",
              "1   APT-C-36  G0099  ['T1059', 'T1105', 'T1036', 'T1571', 'T1027', ...   \n",
              "2       APT1  G0006  ['T1087', 'T1583', 'T1560', 'T1119', 'T1059', ...   \n",
              "3      APT12  G0005      ['T1568', 'T1203', 'T1566', 'T1204', 'T1102']   \n",
              "4      APT16  G0023                                          ['T1584']   \n",
              "\n",
              "                            Associated Groups  \n",
              "0                                         NaN  \n",
              "1                                 Blind Eagle  \n",
              "2  Comment Crew, Comment Group, Comment Panda  \n",
              "3    IXESHE, DynCalc, Numbered Panda, DNSCALC  \n",
              "4                                         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54580054-4567-48da-a378-497e665acc51\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>ID</th>\n",
              "      <th>Tecs Used by Group</th>\n",
              "      <th>Associated Groups</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>admin@338</td>\n",
              "      <td>G0018</td>\n",
              "      <td>['T1087', 'T1059', 'T1203', 'T1083', 'T1036', ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>APT-C-36</td>\n",
              "      <td>G0099</td>\n",
              "      <td>['T1059', 'T1105', 'T1036', 'T1571', 'T1027', ...</td>\n",
              "      <td>Blind Eagle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>APT1</td>\n",
              "      <td>G0006</td>\n",
              "      <td>['T1087', 'T1583', 'T1560', 'T1119', 'T1059', ...</td>\n",
              "      <td>Comment Crew, Comment Group, Comment Panda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>APT12</td>\n",
              "      <td>G0005</td>\n",
              "      <td>['T1568', 'T1203', 'T1566', 'T1204', 'T1102']</td>\n",
              "      <td>IXESHE, DynCalc, Numbered Panda, DNSCALC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>APT16</td>\n",
              "      <td>G0023</td>\n",
              "      <td>['T1584']</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54580054-4567-48da-a378-497e665acc51')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54580054-4567-48da-a378-497e665acc51 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54580054-4567-48da-a378-497e665acc51');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ],
      "source": [
        "group.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqccHOoLpO0v"
      },
      "outputs": [],
      "source": [
        "compaigns=[]\n",
        "for i in group['Associated Groups']:\n",
        "  if type(i)!=float:\n",
        "      compaigns=compaigns+i.split(',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nCgoHGkqk5G"
      },
      "outputs": [],
      "source": [
        "for i in range (len(compaigns)):\n",
        "  compaigns[i]=remove_space(compaigns[i])\n",
        "  compaigns[i]=compaigns[i].lower()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=data"
      ],
      "metadata": {
        "id": "zKKul9xrepqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl1urQWPdz4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794d5f29-c4a8-4e14-b46a-44f192a18521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: FutureWarning: The default value of regex will change from True to False in a future version.\n"
          ]
        }
      ],
      "source": [
        "df['source']=df['source'].str.replace(')','')\n",
        "df['source']=df['source'].str.replace('(','')\n",
        "df['source']=df['source'].str.replace('[','')\n",
        "df['source']=df['source'].str.replace(']','')\n",
        "df['source']=df['source'].str.replace(\"'s\",'')\n",
        "df['source']=df['source'].str.replace(\"'\",' ')\n",
        "df['target']=df['target'].str.replace(')','')\n",
        "df['target']=df['target'].str.replace('(','')\n",
        "df['target']=df['target'].str.replace('[','')\n",
        "df['target']=df['target'].str.replace(']','')\n",
        "df['target']=df['target'].str.replace(\"'s\",'')\n",
        "df['target']=df['target'].str.replace(\"'\",' ')\n",
        "df['target']=df['target'].str.replace('\"','')\n",
        "df['source']=df['source'].str.replace('\"','')\n",
        "df['target']=df['target'].str.replace('{','')\n",
        "df['target']=df['target'].str.replace('}','')\n",
        "df['source']=df['source'].str.replace('{','')\n",
        "df['source']=df['source'].str.replace('}','')\n",
        "df['target']=df['target'].str.replace('*','')\n",
        "df['target']=df['target'].str.replace('\"','')\n",
        "df['source']=df['source'].str.replace('*','')\n",
        "df['source']=df['source'].str.replace('\"','')\n",
        "df['target']=df['target'].str.replace(\"\\\\\",'')\n",
        "df['source']=df['source'].str.replace(\"\\\\\",'')\n",
        "df['target']=df['target'].str.replace(\"\\ \",'')\n",
        "df['source']=df['source'].str.replace(\"\\ \",'')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHfHC--LWrPs"
      },
      "outputs": [],
      "source": [
        "df.loc[df.source.str.lower().isin(compaigns), 'tag1']= 'CAMPAIGN'\n",
        "df.loc[df.target.str.lower().isin(compaigns), 'tag2']= 'CAMPAIGN'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CG2wSok4ewL7"
      },
      "outputs": [],
      "source": [
        "df.loc[df.tag1=='COMPAIGN', 'tag1']='CAMPAIGN'\n",
        "df.loc[df.tag2=='COMPAIGN', 'tag2']='CAMPAIGN'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7qB1npCMJZS6",
        "outputId": "b530a254-2482-42b3-90cf-84da50743572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            source       tag1      relation_label      target       tag2\n",
              "0        Microsoft        ORG          hasproduct     Windows    PRODUCT\n",
              "1        Microsoft        ORG          hasproduct      PsExec    PRODUCT\n",
              "2            Adobe        ORG          hasproduct     Acrobat    PRODUCT\n",
              "3      BlackEnergy        ORG          hasproduct     Trojans    PRODUCT\n",
              "4             Tsai   ATTACKER   hasattacklocation       China        LOC\n",
              "...            ...        ...                 ...         ...        ...\n",
              "21894          107    MALWARE           indicates         181  INDICATOR\n",
              "21895     xxxxxxxx  INDICATOR           indicates           /  INDICATOR\n",
              "21896        index  INDICATOR  hascharacteristics       index  INDICATOR\n",
              "21897          www  INDICATOR          hasproduct  trendmicro  INDICATOR\n",
              "21898         john    MALWARE       hasattacktime        2015       DATE\n",
              "\n",
              "[21899 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab7fa6ee-788a-4152-a7ba-26fd3a47d68f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>tag1</th>\n",
              "      <th>relation_label</th>\n",
              "      <th>target</th>\n",
              "      <th>tag2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Microsoft</td>\n",
              "      <td>ORG</td>\n",
              "      <td>hasproduct</td>\n",
              "      <td>Windows</td>\n",
              "      <td>PRODUCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Microsoft</td>\n",
              "      <td>ORG</td>\n",
              "      <td>hasproduct</td>\n",
              "      <td>PsExec</td>\n",
              "      <td>PRODUCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adobe</td>\n",
              "      <td>ORG</td>\n",
              "      <td>hasproduct</td>\n",
              "      <td>Acrobat</td>\n",
              "      <td>PRODUCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BlackEnergy</td>\n",
              "      <td>ORG</td>\n",
              "      <td>hasproduct</td>\n",
              "      <td>Trojans</td>\n",
              "      <td>PRODUCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tsai</td>\n",
              "      <td>ATTACKER</td>\n",
              "      <td>hasattacklocation</td>\n",
              "      <td>China</td>\n",
              "      <td>LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21894</th>\n",
              "      <td>107</td>\n",
              "      <td>MALWARE</td>\n",
              "      <td>indicates</td>\n",
              "      <td>181</td>\n",
              "      <td>INDICATOR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21895</th>\n",
              "      <td>xxxxxxxx</td>\n",
              "      <td>INDICATOR</td>\n",
              "      <td>indicates</td>\n",
              "      <td>/</td>\n",
              "      <td>INDICATOR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21896</th>\n",
              "      <td>index</td>\n",
              "      <td>INDICATOR</td>\n",
              "      <td>hascharacteristics</td>\n",
              "      <td>index</td>\n",
              "      <td>INDICATOR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21897</th>\n",
              "      <td>www</td>\n",
              "      <td>INDICATOR</td>\n",
              "      <td>hasproduct</td>\n",
              "      <td>trendmicro</td>\n",
              "      <td>INDICATOR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21898</th>\n",
              "      <td>john</td>\n",
              "      <td>MALWARE</td>\n",
              "      <td>hasattacktime</td>\n",
              "      <td>2015</td>\n",
              "      <td>DATE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21899 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab7fa6ee-788a-4152-a7ba-26fd3a47d68f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab7fa6ee-788a-4152-a7ba-26fd3a47d68f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab7fa6ee-788a-4152-a7ba-26fd3a47d68f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('df.csv')"
      ],
      "metadata": {
        "id": "3N-rrxXKfH55"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "gQ52tc_2Y2dH",
        "1aUhP-rWY_iz",
        "YS9fedEh4oB9",
        "o2RzEngCaxSy",
        "fdABbgSba3BK",
        "BbcA6-xKkFMX",
        "UKp9DjPHkLbi",
        "T1g9zv0FkVBz",
        "Subt2FHrkZ0Z",
        "r1js2OnXkezk",
        "NsmsigSiklqc",
        "XM3kB_Eckt27",
        "dSYWIe_Mkyz0",
        "faQq5UBkk3UY",
        "BtLLF0rGk6mF"
      ],
      "machine_shape": "hm",
      "name": "Input for KG construction task.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}